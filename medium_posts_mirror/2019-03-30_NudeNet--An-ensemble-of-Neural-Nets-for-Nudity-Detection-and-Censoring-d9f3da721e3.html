<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>NudeNet: An ensemble of Neural Nets for Nudity Detection and Censoring</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">NudeNet: An ensemble of Neural Nets for Nudity Detection and Censoring</h1>
</header>
<section data-field="subtitle" class="p-summary">
Part 1: Nudity detection with image classification
</section>
<section data-field="body" class="e-content">
<section name="8b5b" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="e426" id="e426" class="graf graf--h3 graf--leading graf--title"><strong class="markup--strong markup--h3-strong">NudeNet</strong>: An ensemble of Neural Nets for Nudity Detection and Censoring</h3><h3 name="e9b1" id="e9b1" class="graf graf--h3 graf-after--h3"><strong class="markup--strong markup--h3-strong">Part 1</strong>: Nudity detection with image classification</h3><p name="b337" id="b337" class="graf graf--p graf-after--h3">With the advent of excellent DL libraries and plethora of open-source implementations and papers, <strong class="markup--strong markup--p-strong">Image Classification is very easy to implement</strong>. That is, <strong class="markup--strong markup--p-strong">if you have the dataset. </strong>There are plenty of open datasets available to test and refine classification models. But obtaining a task specific dataset is tough. Nudity/ NSFW detection is one such use-case where there are no practically useful open datasets available.</p><p name="d65b" id="d65b" class="graf graf--p graf-after--p">In the first part of this two part project, I collect data for and implement nudity detection using Image Classification. My goal is to build a good open source dataset for this use-case and provide a pre-trained model for the same. In the second part I aim to implement and open-source private/ exposed part detection using Object Detection.</p><blockquote name="0b65" id="0b65" class="graf graf--blockquote graf-after--p"><strong class="markup--strong markup--blockquote-strong">The Why: </strong>I sincerely believe in not re-inventing the wheel. At the time of starting this project, Yahoo’s open_nsfw is the only decently working nudity detection module available. It is quiet outdated and the data isn’t available to public. There is <strong class="markup--strong markup--blockquote-strong">no (AFAIK) open-source project available for censoring of exposed parts</strong>.</blockquote><p name="8bb8" id="8bb8" class="graf graf--p graf-after--blockquote"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Collecting Nude images</em></strong><em class="markup--em markup--p-em">:</em> For getting these images, I started with Reddit. I made a list of NSFW sub-reddits mostly collected from <a href="https://scrolller.com/nsfw" data-href="https://scrolller.com/nsfw" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">the website scrolller</a> (thanks to the hard work of <a href="https://www.reddit.com/user/faroix" data-href="https://www.reddit.com/user/faroix" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">/u/faroix</a>). After using the excellent <a href="https://github.com/RipMeApp/ripme" data-href="https://github.com/RipMeApp/ripme" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">RipMe</a> application to download ~1000 images from each of these sub-reddits and going through them (not recommended for the lighthearted), I found a major problem with this data.<br>Almost all the images collected from these sub-reddits are of very high quality. In fact, combined these images came out to ~260 GB. This isn’t ideal, since <strong class="markup--strong markup--p-strong">a lot of porn is of potato quality</strong>. To balance this out, I crawled thumbnails of videos from PornHub.<br>While I was doing this, another open-source enthusiast <a href="https://github.com/GantMan" data-href="https://github.com/GantMan" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">GantMan</a> open-sourced a model trained on the data collected by <a href="https://github.com/alexkimxyz/nsfw_data_scraper" data-href="https://github.com/alexkimxyz/nsfw_data_scraper" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">alexkimxyz</a>. So, I contacted GantMan and obtained the dataset he used.</p><pre name="efe4" id="efe4" class="graf graf--pre graf-after--p"># Resizing and removing duplicates<br>mogrify -geometry x320 *<br>fdupes -rdN ./</pre><p name="68a5" id="68a5" class="graf graf--p graf-after--pre">After using the above two commands to reduce normalize the images and remove duplicates, I ended up with <strong class="markup--strong markup--p-strong">1,78,601 from PornHub</strong>, <strong class="markup--strong markup--p-strong">1,21,644 from Reddit</strong> and <strong class="markup--strong markup--p-strong">1,30,266 from GantMan’s dataset</strong>.</p><p name="db58" id="db58" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Collecting Safe images:</em> </strong>After I was done with collection of nude images, I though that the tough part was over and I couldn’t be more wrong. Collecting some random images would be very easy, but doing so will result in the classifier learning to classify all humans into nude category. Since, neural networks try to minimize loss, <strong class="markup--strong markup--p-strong">not having a lot of human images in the “safe” category will result in our model being a “Human detector”</strong> (which is an easy task) rather than being a “nudity detector”.</p><p name="3ed4" id="3ed4" class="graf graf--p graf-after--p">For building a good classifier, I needed lot of non-nude images that had people in them. After going through GantMan’s sfw data, I observed that though the total number of images is decent, the number of images with people in them was very less.<br>After some thinking, I realized that Facebook is a great place to collect images with people in them. So, I crawled Facebook profile pictures using their Graph API. I also made a list of safe sub-reddits and crawled ~1000 images from each one using ripme. After resizing and cleaning, I ended up with <strong class="markup--strong markup--p-strong">68,948 from Facebook</strong>, <strong class="markup--strong markup--p-strong">98,359 from GantMan’s dataset</strong> and <strong class="markup--strong markup--p-strong">55,137 from Reddit.</strong></p><p name="4c72" id="4c72" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Processing Pipeline: </em></strong>I used the excellent image augmentation library <a href="https://github.com/mdbloice/Augmentor" data-href="https://github.com/mdbloice/Augmentor" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Augmentor</a> with some added fail-safes for on the fly image augmentation to use with Keras’s fit_generator.</p><p name="d638" id="d638" class="graf graf--p graf-after--p">The following snippet is the augmentation used for training data.</p><pre name="d095" id="d095" class="graf graf--pre graf-after--p"># Random rotation, flips, zoom, distortion, contrast, skew and brightness<br>pipeline.rotate(probability=0.2, max_left_rotation=20, max_right_rotation=20)<br>pipeline.flip_left_right(probability=0.4)<br>pipeline.flip_top_bottom(probability=0.8)<br>pipeline.zoom(probability=0.2, min_factor=1.1, max_factor=1.5)<br>pipeline.random_distortion(probability=0.2, grid_width=4, grid_height=4, magnitude=8)pipeline.random_brightness(probability=0.2, min_factor=0.5, max_factor=3)pipeline.random_color(probability=0.2, min_factor=0.5, max_factor=3)<br>pipeline.random_contrast(probability=0.2, min_factor=0.5, max_factor=3)<br>pipeline.skew(probability=0.2, magnitude=0.4)</pre><p name="178c" id="178c" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">The Training: </em></strong>For the training I rented a machine with GTX 1080Ti, with 12GB of vram and 64GB system memory from vast.ai for 0.11$ per hour. I was able to to use a batch size of 32 with <a href="https://towardsdatascience.com/review-xception-with-depthwise-separable-convolution-better-than-inception-v3-image-dc967dd42568" data-href="https://towardsdatascience.com/review-xception-with-depthwise-separable-convolution-better-than-inception-v3-image-dc967dd42568" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Xception</a> and 256x256 input image size.</p><p name="310b" id="310b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Note: </strong>The implementations of image classification models provided in Keras’s applications, do not use any type of regularization. For adding regularization (dropout or l2) loop over each layer and add regularization.</p><pre name="92bc" id="92bc" class="graf graf--pre graf-after--p"><code class="markup--code markup--pre-code"># For l2<br>for layer in model.layers: layer.W_regularizer = l2(..)<br># Or for dropout add dropout between the fully connected layers and redefine the model using functional API.</code></pre><p name="fba0" id="fba0" class="graf graf--p graf-after--pre">Using SGD with momentum, the model converges at 0.9347 accuracy on GantMan’s data.</p><p name="7255" id="7255" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Evaluation: </strong>Finding the right data for evaluating a nudtiy detection module is very tough. Nudity/ Porn has thousands of variations (See <a href="https://www.urbandictionary.com/define.php?term=Rule%2034" data-href="https://www.urbandictionary.com/define.php?term=Rule%2034" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Rule 34</a>) and building a comprehensive test data is next to impossible. But, just to get a simple idea of how this is working, I use the data collected by Aditya at <a href="https://towardsdatascience.com/comparison-of-the-best-nsfw-image-moderation-apis-2018-84be8da65303" data-href="https://towardsdatascience.com/comparison-of-the-best-nsfw-image-moderation-apis-2018-84be8da65303" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://towardsdatascience.com/comparison-of-the-best-nsfw-image-moderation-apis-2018-84be8da65303</a>. Note that, even this is not a good test data. The best way to test and improve something like this is by community help. Since, his test data is in different categories, I map the categories <strong class="markup--strong markup--p-strong">“nsfw_porn”, “nsfw_explicit_nudity”, “nsfw_simulated_porn” to “nude”</strong> category and the category <strong class="markup--strong markup--p-strong">“sfw” to “safe”</strong>.</p><figure name="8770" id="8770" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 516px; max-height: 137px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 26.6%;"></div><img class="graf-image" data-image-id="1*rYQq9oHfNvrgrMokZpDf3A.png" data-width="516" data-height="137" src="https://cdn-images-1.medium.com/max/800/1*rYQq9oHfNvrgrMokZpDf3A.png"></div><figcaption class="imageCaption">Precision and Recall of NudeNet’s classifier</figcaption></figure><p name="f91a" id="f91a" class="graf graf--p graf-after--figure">For testing with GantMan’s test data, I map the the classes “hentai”, “porn” to “nude” category and “drawings”, “neutral”, “sexy” to safe category. This is because, according to his definition of classes nudes of people will be labelled as “porn” and cartoon nudes will be labelled as “hentai”.</p><figure name="5934" id="5934" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 452px; max-height: 119px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 26.3%;"></div><img class="graf-image" data-image-id="1*JoBSB6MzTbcHJJoIJGWbog.png" data-width="452" data-height="119" src="https://cdn-images-1.medium.com/max/800/1*JoBSB6MzTbcHJJoIJGWbog.png"></div><figcaption class="imageCaption">Precision and Recall of GantMan’s nsfw_model</figcaption></figure><figure name="de04" id="de04" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 440px; max-height: 120px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 27.3%;"></div><img class="graf-image" data-image-id="1*y_kC3vN5ex_z1XrgsK-5YA.png" data-width="440" data-height="120" src="https://cdn-images-1.medium.com/max/800/1*y_kC3vN5ex_z1XrgsK-5YA.png"></div><figcaption class="imageCaption">Precision and Recall of Yahoo’s Open NSFW</figcaption></figure><p name="4e70" id="4e70" class="graf graf--p graf-after--figure">Funnily enough, All the three projects get similar scores, although they fail at different images. For example, <strong class="markup--strong markup--p-strong">GantMan’s model funnily fails with Jeff Goldblum’s images where as NudeNet doesn’t</strong>. Similarly, NudeNet fails with some images, for which GantMan’s model doesn’t. <strong class="markup--strong markup--p-strong">In the couple of months of working on this project, I came across a lot of images for which Google’s cloud vision api fails miserably.</strong> Because most of these images are NSFW (duh!), I am unable to add them here. If you want to take a look at some of these examples, please leave a comment.</p><p name="db5b" id="db5b" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Update: </strong>I was able to find another manually curated dataset for testing. This dataset is available at <a href="https://dataturks.com/projects/Mohan/NSFW%28Nudity%20Detection%29%20Image%20Moderation%20Datatset" data-href="https://dataturks.com/projects/Mohan/NSFW(Nudity%20Detection)%20Image%20Moderation%20Datatset" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://dataturks.com/projects/Mohan/NSFW(Nudity%20Detection)%20Image%20Moderation%20Datatset</a> .</p><figure name="d727" id="d727" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 463px; max-height: 154px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 33.300000000000004%;"></div><img class="graf-image" data-image-id="1*2HNxom63gSHgUZvcnADgIQ.png" data-width="463" data-height="154" src="https://cdn-images-1.medium.com/max/800/1*2HNxom63gSHgUZvcnADgIQ.png"></div><figcaption class="imageCaption">NudeNet precision and recall on the dataturks dataset</figcaption></figure><figure name="ee40" id="ee40" class="graf graf--figure graf-after--figure"><div class="aspectRatioPlaceholder is-locked" style="max-width: 472px; max-height: 149px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 31.6%;"></div><img class="graf-image" data-image-id="1*GK7Ht8onoRi3n4Bp1U0NEw.png" data-width="472" data-height="149" src="https://cdn-images-1.medium.com/max/800/1*GK7Ht8onoRi3n4Bp1U0NEw.png"></div><figcaption class="imageCaption">GantMan’s nsfw_model precision and recall on the dataturks dataset</figcaption></figure><p name="d8ff" id="d8ff" class="graf graf--p graf-after--figure">The project can be found at <a href="https://github.com/bedapudi6788/NudeNet" data-href="https://github.com/bedapudi6788/NudeNet" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://github.com/bedapudi6788/NudeNet</a></p><p name="df4c" id="df4c" class="graf graf--p graf-after--p">The pre-trained models at <a href="https://github.com/bedapudi6788/NudeNet-models/" data-href="https://github.com/bedapudi6788/NudeNet-models/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://github.com/bedapudi6788/NudeNet-models/</a></p><p name="675e" id="675e" class="graf graf--p graf-after--p">To install and use NudeNet, take a look at the following snippet.</p><pre name="b4ee" id="b4ee" class="graf graf--pre graf-after--p"># installing the project<br>pip install git+<a href="https://github.com/bedapudi6788/NudeNet" data-href="https://github.com/bedapudi6788/NudeNet" class="markup--anchor markup--pre-anchor" rel="nofollow noopener" target="_blank">https://github.com/bedapudi6788/NudeNet</a></pre><pre name="04e2" id="04e2" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code"># Using the classifier<br>from NudeNet import NudeClassifier<br>classifier = NudeClassifier(&#39;classifier_checkpoint_path&#39;)<br>classifier.classify(&#39;path_to_nude_image&#39;)</code></pre><p name="550b" id="550b" class="graf graf--p graf-after--pre graf--trailing">In the second part of this post, I implement Exposed Part Detection and Censoring using Object Detection. Please find the second part of this post at <a href="https://medium.com/@praneethbedapudi/nudenet-an-ensemble-of-neural-nets-for-nudity-detection-and-censoring-c8fcefa6cc92?source=friends_link&amp;sk=f0a4786bf005cd4b7e89cf625f109af0" data-href="https://medium.com/@praneethbedapudi/nudenet-an-ensemble-of-neural-nets-for-nudity-detection-and-censoring-c8fcefa6cc92?source=friends_link&amp;sk=f0a4786bf005cd4b7e89cf625f109af0" class="markup--anchor markup--p-anchor" rel="nofollow" target="_blank">https://medium.com/@praneethbedapudi/nudenet-an-ensemble-of-neural-nets-for-nudity-detection-and-censoring-c8fcefa6cc92?source=friends_link&amp;sk=f0a4786bf005cd4b7e89cf625f109af0</a></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@praneethbedapudi" class="p-author h-card">Praneeth Bedapudi</a> on <a href="https://medium.com/p/d9f3da721e3"><time class="dt-published" datetime="2019-03-30T07:23:40.687Z">March 30, 2019</time></a>.</p><p><a href="https://medium.com/@praneethbedapudi/nudenet-an-ensemble-of-neural-nets-for-nudity-detection-and-censoring-d9f3da721e3" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on February 21, 2020.</p></footer></article></body></html>